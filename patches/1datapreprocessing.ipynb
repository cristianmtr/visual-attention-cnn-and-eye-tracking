{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import glob\n",
    "import sys\n",
    "from scipy import io\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import keras\n",
    "from sklearn import preprocessing\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POET_DIR = \"D:/data/POETdataset/\"\n",
    "PATCHES_FILE = os.path.join(POET_DIR, \"all_patches_list.npy\")\n",
    "LABELS_FILE = os.path.join(POET_DIR, \"all_labels_list.npy\")\n",
    "pascal_images = os.path.join(POET_DIR, 'PascalImages')\n",
    "CLASS2IDX_FILE = os.path.join(POET_DIR, 'class2idx.npy')\n",
    "IDX2CLASS_FILE = os.path.join(POET_DIR, 'idx2class.npy')\n",
    "PATCH_SIZE = 32\n",
    "HALF_PATCH = PATCH_SIZE//2\n",
    "DATASET_SIZE = 6270\n",
    "VALIDATION_PERC = 0.2\n",
    "MAX_GAZE_POINTS = 3 # TEMPORARY\n",
    "MIN_GAZE_POINTS = 3\n",
    "VGG_NR_FEATURES = 512\n",
    "user_index = 0 # TEMPORARY\n",
    "BATCH_SIZE = 50\n",
    "os.chdir(POET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(POET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATCH EXTRACTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [a.split(\"_\")[1].split(\".mat\")[0] for a in glob.glob(\"etData/*\")]\n",
    "idx2class = {i:c for i, c in enumerate(classes)}\n",
    "class2idx = {c:i for i, c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixation_within_image(fx, fy, dims):\n",
    "#   print(dims)\n",
    "  if fx < 0:\n",
    "    return False\n",
    "  if fx > dims[0]:\n",
    "    return False\n",
    "  if fy < 0:\n",
    "    return False\n",
    "  if fy > dims[1]:\n",
    "    return False\n",
    "\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_fixations(fixR, fixL, dims):\n",
    "    # ger average of fixations between right and left eye\n",
    "    fix = []\n",
    "    for i in range(len(fixR)):\n",
    "        fR = fixR[i]\n",
    "        fL = fixL[i]\n",
    "        fx = None\n",
    "        fy = None\n",
    "        # no fixations outside\n",
    "        if np.isnan(fR[0]):\n",
    "            fx = fL[0]\n",
    "            fy = fL[1]\n",
    "        elif np.isnan(fL[0]):\n",
    "            fx = fR[0]\n",
    "            fy = fR[1]\n",
    "        else:\n",
    "            fx = np.mean([fR[0],fL[0]])\n",
    "            fy = np.mean([fR[1],fL[1]])\n",
    "        if fixation_within_image(fx, fy, dims):\n",
    "            fix.append([fx,fy])\n",
    "\n",
    "    fix = np.array(fix)\n",
    "    return fix[:MAX_GAZE_POINTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixations(filename, classname, dims):\n",
    "    filename = filename.split(\"%s_\" %classname)[1]\n",
    "    filename = filename.split('.')[0]\n",
    "    c_instances = io.loadmat(os.path.join(POET_DIR,'etData','etData_%s.mat' %classname), squeeze_me=True)['etData']\n",
    "    user_index = 1\n",
    "    for i in c_instances:\n",
    "        if filename == i['filename']:\n",
    "            fixR = i['fixations'][user_index]['imgCoord']['fixR'].tolist()['pos'].tolist()\n",
    "            fixL = i['fixations'][user_index]['imgCoord']['fixL'].tolist()['pos'].tolist()\n",
    "            if len(fixL.shape) < 2:\n",
    "                return None\n",
    "            fix = get_avg_fixations(fixR, fixL, dims)\n",
    "            return fix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_patches(filename, classname):\n",
    "    img_src = cv2.imread(filename, )\n",
    "\n",
    "    img = np.zeros((img_src.shape[0]+PATCH_SIZE, img_src.shape[1]+PATCH_SIZE, 3), dtype=float)\n",
    "    img[HALF_PATCH:HALF_PATCH+img_src.shape[0],HALF_PATCH:img_src.shape[1]+HALF_PATCH] = img_src\n",
    "\n",
    "    fix = get_fixations(filename, classname, (img_src.shape[0], img_src.shape[1]))\n",
    "    if fix is None or len(fix) < MIN_GAZE_POINTS:\n",
    "        return None\n",
    "\n",
    "    patches = np.zeros((len(fix), PATCH_SIZE, PATCH_SIZE, 3), dtype=int)\n",
    "\n",
    "    for i, f in enumerate(fix):\n",
    "        fx = math.floor(f[0]) + HALF_PATCH # to account for paddings\n",
    "        fy = math.floor(f[1]) + HALF_PATCH\n",
    "        p = img[fx-HALF_PATCH:fx+HALF_PATCH,fy-HALF_PATCH:fy+HALF_PATCH]\n",
    "        assert p.shape==(PATCH_SIZE, PATCH_SIZE, 3), 'file \"%s\" of class %s has a patch of shape %s' %(filename, classname, p.shape)\n",
    "        patches[i] = p\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STORE ALL FEATURES OF ALL PATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN for extracting features of a patch\n",
    "vgg16 = keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(32,32,3), pooling='max', classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(os.path.join(pascal_images, \"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_instances = len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████████▌                                                                                                                                                                                   | 348/6270 [01:48<30:39,  3.22it/s]"
     ]
    }
   ],
   "source": [
    "all_patches_list = []\n",
    "all_labels_list = []\n",
    "\n",
    "dropped_list = 0\n",
    "ids = []\n",
    "for i, fn in enumerate(tqdm.tqdm(filenames)):\n",
    "    for cname in classes:\n",
    "        if cname in fn:\n",
    "            filename = os.path.abspath(os.path.join(pascal_images, fn))\n",
    "            patches = gen_patches(filename, cname)\n",
    "            if patches is not None:\n",
    "                all_patches_list.append(patches)\n",
    "                all_labels_list.append(class2idx[cname])\n",
    "                ids.append(filename)\n",
    "            else:\n",
    "                dropped_list += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patches_list = np.array(all_patches_list)\n",
    "all_labels_list = np.array(all_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_list + len(all_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(all_patches_list[220,0]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids[220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patches_list[220,1].min(), all_patches_list[221,2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_labels_list', all_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_patches_list', all_patches_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all_patches_ids', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
