{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "from scipy import io\n",
    "import math\n",
    "import random\n",
    "import keras\n",
    "from sklearn import preprocessing\n",
    "from glob import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "POET_DIR = \"D:/data/POETdataset/\"\n",
    "PATCHES_FILE = os.path.join(POET_DIR, \"x.npy\")\n",
    "LABELS_FILE = os.path.join(POET_DIR, 'y.npy')\n",
    "pascal_images = os.path.join(POET_DIR, 'PascalImages')\n",
    "PATCH_SIZE = 32\n",
    "HALF_PATCH = PATCH_SIZE//2\n",
    "DATASET_SIZE = 6270\n",
    "VALIDATION_PERC = 0.2\n",
    "MAX_GAZE_POINTS = 3 # TEMPORARY\n",
    "MIN_GAZE_POINTS = 3\n",
    "VGG_NR_FEATURES = 512\n",
    "user_index = 0 # TEMPORARY\n",
    "BATCH_SIZE = 50\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(POET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [a.split(\"_\")[1].split(\".mat\")[0] for a in glob(\"etData/*\")]\n",
    "idx2class = {i:c for i, c in enumerate(classes)}\n",
    "class2idx = {c:i for i, c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_model = keras.applications.ResNet50(weights='imagenet', include_top=False, pooling='max')\n",
    "pp_func = keras.applications.resnet50.preprocess_input\n",
    "\n",
    "features_extractor_model = keras.models.Sequential()\n",
    "features_extractor_model.add(keras.layers.Lambda(pp_func,name='preprocessing',input_shape=(IMG_SIZE,IMG_SIZE,3)))\n",
    "features_extractor_model.add(learned_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We store the feature vectors for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aeroplane',\n",
       " 'bicycle',\n",
       " 'boat',\n",
       " 'cat',\n",
       " 'cow',\n",
       " 'diningtable',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'motorbike',\n",
       " 'sofa']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeroplane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████████▍                                                                                                                                                                              | 1/10 [00:11<01:45, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████████████▊                                                                                                                                                           | 2/10 [00:19<01:24, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████████████████████████████████████▏                                                                                                                                       | 3/10 [00:26<01:05,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                    | 4/10 [00:40<01:05, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                 | 5/10 [00:45<00:44,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diningtable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                             | 6/10 [00:52<00:34,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 7/10 [01:10<00:33, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 8/10 [01:17<00:20, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motorbike\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                   | 9/10 [01:25<00:09,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sofa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:32<00:00,  8.59s/it]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i, cname in enumerate(tqdm.tqdm(classes)):\n",
    "    print(cname)\n",
    "    class_files = glob(\"PascalImages/%s*\" %cname)\n",
    "    files_loaded = [keras.preprocessing.image.img_to_array(\n",
    "        keras.preprocessing.image.load_img(file_, target_size=(IMG_SIZE, IMG_SIZE, 3)\n",
    "                                          )\n",
    "    ) \n",
    "                    for file_ in class_files\n",
    "                   ]\n",
    "    feature_vec = features_extractor_model.predict(np.array(files_loaded),verbose=1)\n",
    "    x.append(feature_vec)\n",
    "    y.append([class2idx[cname]]*len(class_files))\n",
    "x = np.concatenate(x)\n",
    "y = np.concatenate(y)\n",
    "                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6270, 2048)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('baselinemodel-images-features.npy',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('baselinemodel-labels.npy',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 666.,  536.,  504., 1051.,  301.,  498., 1257.,  480.,  510.,\n",
       "         467.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img = np.zeros((len(x), IMG_SIZE, IMG_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "y = y.reshape(-1,1)\n",
    "enc.fit(y)\n",
    "y_onehot = enc.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y.npy', y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6270, 2048)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y_onehot.todense(), test_size=0.1, stratify=y_onehot.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(128, activation='relu', input_shape=(2048,)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "optm = keras.optimizers.rmsprop(lr=0.00001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optm,\n",
    "                metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5643 samples, validate on 627 samples\n",
      "Epoch 1/100\n",
      "5643/5643 [==============================] - 1s 133us/step - loss: 0.6802 - acc: 0.8159 - val_loss: 1.0412 - val_acc: 0.7735\n",
      "Epoch 2/100\n",
      "5643/5643 [==============================] - 1s 133us/step - loss: 0.6439 - acc: 0.8258 - val_loss: 1.0256 - val_acc: 0.7735\n",
      "Epoch 3/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.6127 - acc: 0.8348 - val_loss: 1.0094 - val_acc: 0.7687\n",
      "Epoch 4/100\n",
      "5643/5643 [==============================] - 1s 133us/step - loss: 0.5832 - acc: 0.8377 - val_loss: 0.9931 - val_acc: 0.7703\n",
      "Epoch 5/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.5555 - acc: 0.8469 - val_loss: 0.9875 - val_acc: 0.7703\n",
      "Epoch 6/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.5307 - acc: 0.8556 - val_loss: 0.9694 - val_acc: 0.7815\n",
      "Epoch 7/100\n",
      "5643/5643 [==============================] - 1s 133us/step - loss: 0.5069 - acc: 0.8596 - val_loss: 0.9738 - val_acc: 0.7735\n",
      "Epoch 8/100\n",
      "5643/5643 [==============================] - 1s 136us/step - loss: 0.4841 - acc: 0.8682 - val_loss: 0.9536 - val_acc: 0.7783\n",
      "Epoch 9/100\n",
      "5643/5643 [==============================] - 1s 134us/step - loss: 0.4658 - acc: 0.8728 - val_loss: 0.9516 - val_acc: 0.7863\n",
      "Epoch 10/100\n",
      "5643/5643 [==============================] - 1s 134us/step - loss: 0.4453 - acc: 0.8781 - val_loss: 0.9355 - val_acc: 0.7799\n",
      "Epoch 11/100\n",
      "5643/5643 [==============================] - 1s 131us/step - loss: 0.4268 - acc: 0.8820 - val_loss: 0.9332 - val_acc: 0.7783\n",
      "Epoch 12/100\n",
      "5643/5643 [==============================] - 1s 142us/step - loss: 0.4100 - acc: 0.8880 - val_loss: 0.9236 - val_acc: 0.7815\n",
      "Epoch 13/100\n",
      "5643/5643 [==============================] - 1s 135us/step - loss: 0.3920 - acc: 0.8944 - val_loss: 0.9221 - val_acc: 0.7879\n",
      "Epoch 14/100\n",
      "5643/5643 [==============================] - 1s 134us/step - loss: 0.3771 - acc: 0.8983 - val_loss: 0.9176 - val_acc: 0.7879\n",
      "Epoch 15/100\n",
      "5643/5643 [==============================] - 1s 135us/step - loss: 0.3630 - acc: 0.9001 - val_loss: 0.9110 - val_acc: 0.7831\n",
      "Epoch 16/100\n",
      "5643/5643 [==============================] - 1s 140us/step - loss: 0.3473 - acc: 0.9050 - val_loss: 0.9190 - val_acc: 0.7815\n",
      "Epoch 17/100\n",
      "5643/5643 [==============================] - 1s 136us/step - loss: 0.3352 - acc: 0.9087 - val_loss: 0.9142 - val_acc: 0.7847\n",
      "Epoch 18/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.3215 - acc: 0.9141 - val_loss: 0.9004 - val_acc: 0.7895\n",
      "Epoch 19/100\n",
      "5643/5643 [==============================] - 1s 137us/step - loss: 0.3091 - acc: 0.9176 - val_loss: 0.9087 - val_acc: 0.7927\n",
      "Epoch 20/100\n",
      "5643/5643 [==============================] - 1s 128us/step - loss: 0.2971 - acc: 0.9203 - val_loss: 0.9025 - val_acc: 0.7879\n",
      "Epoch 21/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.2847 - acc: 0.9250 - val_loss: 0.9052 - val_acc: 0.7847\n",
      "Epoch 22/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.2773 - acc: 0.9254 - val_loss: 0.8848 - val_acc: 0.7974\n",
      "Epoch 23/100\n",
      "5643/5643 [==============================] - 1s 135us/step - loss: 0.2642 - acc: 0.9321 - val_loss: 0.8879 - val_acc: 0.7927\n",
      "Epoch 24/100\n",
      "5643/5643 [==============================] - 1s 137us/step - loss: 0.2553 - acc: 0.9334 - val_loss: 0.8861 - val_acc: 0.7927\n",
      "Epoch 25/100\n",
      "5643/5643 [==============================] - 1s 137us/step - loss: 0.2449 - acc: 0.9369 - val_loss: 0.8979 - val_acc: 0.7959\n",
      "Epoch 26/100\n",
      "5643/5643 [==============================] - 1s 139us/step - loss: 0.2368 - acc: 0.9389 - val_loss: 0.8882 - val_acc: 0.7943\n",
      "Epoch 27/100\n",
      "5643/5643 [==============================] - 1s 133us/step - loss: 0.2277 - acc: 0.9419 - val_loss: 0.8856 - val_acc: 0.7990\n",
      "Epoch 28/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.2198 - acc: 0.9419 - val_loss: 0.8872 - val_acc: 0.7974\n",
      "Epoch 29/100\n",
      "5643/5643 [==============================] - 1s 129us/step - loss: 0.2110 - acc: 0.9444 - val_loss: 0.8860 - val_acc: 0.7943\n",
      "Epoch 30/100\n",
      "5643/5643 [==============================] - 1s 132us/step - loss: 0.2043 - acc: 0.9468 - val_loss: 0.8741 - val_acc: 0.8022\n",
      "Epoch 31/100\n",
      "5643/5643 [==============================] - 1s 132us/step - loss: 0.1969 - acc: 0.9477 - val_loss: 0.8789 - val_acc: 0.8038\n",
      "Epoch 32/100\n",
      "5643/5643 [==============================] - 1s 131us/step - loss: 0.1897 - acc: 0.9488 - val_loss: 0.8878 - val_acc: 0.8022\n",
      "Epoch 33/100\n",
      "5643/5643 [==============================] - 1s 124us/step - loss: 0.1831 - acc: 0.9523 - val_loss: 0.8837 - val_acc: 0.8038\n",
      "Epoch 34/100\n",
      "5643/5643 [==============================] - 1s 134us/step - loss: 0.1766 - acc: 0.9545 - val_loss: 0.8944 - val_acc: 0.8022\n",
      "Epoch 35/100\n",
      "5643/5643 [==============================] - 1s 147us/step - loss: 0.1708 - acc: 0.9541 - val_loss: 0.8817 - val_acc: 0.7990\n",
      "Epoch 36/100\n",
      "5643/5643 [==============================] - 1s 152us/step - loss: 0.1652 - acc: 0.9552 - val_loss: 0.8929 - val_acc: 0.7959\n",
      "Epoch 37/100\n",
      "5643/5643 [==============================] - 1s 135us/step - loss: 0.1590 - acc: 0.9576 - val_loss: 0.8823 - val_acc: 0.8038\n",
      "Epoch 38/100\n",
      "5643/5643 [==============================] - 1s 131us/step - loss: 0.1542 - acc: 0.9582 - val_loss: 0.8825 - val_acc: 0.8038\n",
      "Epoch 39/100\n",
      "5643/5643 [==============================] - 1s 129us/step - loss: 0.1495 - acc: 0.9575 - val_loss: 0.8813 - val_acc: 0.8118\n",
      "Epoch 40/100\n",
      "5643/5643 [==============================] - 1s 126us/step - loss: 0.1436 - acc: 0.9621 - val_loss: 0.8853 - val_acc: 0.8022\n",
      "Epoch 41/100\n",
      "5643/5643 [==============================] - 1s 129us/step - loss: 0.1390 - acc: 0.9628 - val_loss: 0.8882 - val_acc: 0.8054\n",
      "Epoch 42/100\n",
      "5643/5643 [==============================] - 1s 134us/step - loss: 0.1353 - acc: 0.9619 - val_loss: 0.8973 - val_acc: 0.7959\n",
      "Epoch 43/100\n",
      "5643/5643 [==============================] - 1s 124us/step - loss: 0.1307 - acc: 0.9633 - val_loss: 0.9021 - val_acc: 0.7974\n",
      "Epoch 44/100\n",
      "5643/5643 [==============================] - 1s 125us/step - loss: 0.1264 - acc: 0.9663 - val_loss: 0.8913 - val_acc: 0.8006\n",
      "Epoch 45/100\n",
      "5643/5643 [==============================] - 1s 135us/step - loss: 0.1231 - acc: 0.9635 - val_loss: 0.8884 - val_acc: 0.8022\n",
      "Epoch 46/100\n",
      "5643/5643 [==============================] - 1s 134us/step - loss: 0.1187 - acc: 0.9665 - val_loss: 0.8900 - val_acc: 0.8022\n",
      "Epoch 47/100\n",
      "5643/5643 [==============================] - 1s 127us/step - loss: 0.1155 - acc: 0.9665 - val_loss: 0.9002 - val_acc: 0.7974\n",
      "Epoch 48/100\n",
      "5643/5643 [==============================] - 1s 124us/step - loss: 0.1119 - acc: 0.9674 - val_loss: 0.9003 - val_acc: 0.7990\n",
      "Epoch 49/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.1093 - acc: 0.9685 - val_loss: 0.8984 - val_acc: 0.7990\n",
      "Epoch 50/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.1058 - acc: 0.9692 - val_loss: 0.8940 - val_acc: 0.7990\n",
      "Epoch 51/100\n",
      "5643/5643 [==============================] - 1s 128us/step - loss: 0.1026 - acc: 0.9683 - val_loss: 0.8995 - val_acc: 0.8006\n",
      "Epoch 52/100\n",
      "5643/5643 [==============================] - 1s 128us/step - loss: 0.1001 - acc: 0.9718 - val_loss: 0.9001 - val_acc: 0.8022\n",
      "Epoch 53/100\n",
      "5643/5643 [==============================] - 1s 129us/step - loss: 0.0982 - acc: 0.9704 - val_loss: 0.9102 - val_acc: 0.8038\n",
      "Epoch 54/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.0937 - acc: 0.9718 - val_loss: 0.9137 - val_acc: 0.8038\n",
      "Epoch 55/100\n",
      "5643/5643 [==============================] - 1s 129us/step - loss: 0.0931 - acc: 0.9702 - val_loss: 0.9049 - val_acc: 0.8006\n",
      "Epoch 56/100\n",
      "5643/5643 [==============================] - 1s 127us/step - loss: 0.0899 - acc: 0.9727 - val_loss: 0.9048 - val_acc: 0.8038\n",
      "Epoch 57/100\n",
      "5643/5643 [==============================] - 1s 127us/step - loss: 0.0885 - acc: 0.9713 - val_loss: 0.9094 - val_acc: 0.7959\n",
      "Epoch 58/100\n",
      "5643/5643 [==============================] - 1s 132us/step - loss: 0.0862 - acc: 0.9708 - val_loss: 0.9155 - val_acc: 0.7990\n",
      "Epoch 59/100\n",
      "5643/5643 [==============================] - 1s 127us/step - loss: 0.0837 - acc: 0.9724 - val_loss: 0.9209 - val_acc: 0.8054\n",
      "Epoch 60/100\n",
      "5643/5643 [==============================] - 1s 129us/step - loss: 0.0827 - acc: 0.9725 - val_loss: 0.9122 - val_acc: 0.7974\n",
      "Epoch 61/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.0806 - acc: 0.9706 - val_loss: 0.9171 - val_acc: 0.8022\n",
      "Epoch 62/100\n",
      "5643/5643 [==============================] - 1s 139us/step - loss: 0.0789 - acc: 0.9740 - val_loss: 0.9192 - val_acc: 0.7974\n",
      "Epoch 63/100\n",
      "5643/5643 [==============================] - 1s 129us/step - loss: 0.0775 - acc: 0.9748 - val_loss: 0.9186 - val_acc: 0.8038\n",
      "Epoch 64/100\n",
      "5643/5643 [==============================] - 1s 135us/step - loss: 0.0763 - acc: 0.9729 - val_loss: 0.9204 - val_acc: 0.7990\n",
      "Epoch 65/100\n",
      "5643/5643 [==============================] - 1s 131us/step - loss: 0.0744 - acc: 0.9724 - val_loss: 0.9199 - val_acc: 0.8038\n",
      "Epoch 66/100\n",
      "5643/5643 [==============================] - 1s 127us/step - loss: 0.0730 - acc: 0.9731 - val_loss: 0.9225 - val_acc: 0.7990\n",
      "Epoch 67/100\n",
      "5643/5643 [==============================] - 1s 132us/step - loss: 0.0718 - acc: 0.9738 - val_loss: 0.9286 - val_acc: 0.7943\n",
      "Epoch 68/100\n",
      "5643/5643 [==============================] - 1s 133us/step - loss: 0.0709 - acc: 0.9741 - val_loss: 0.9308 - val_acc: 0.7990\n",
      "Epoch 69/100\n",
      "5643/5643 [==============================] - 1s 129us/step - loss: 0.0694 - acc: 0.9725 - val_loss: 0.9346 - val_acc: 0.8006\n",
      "Epoch 70/100\n",
      "5643/5643 [==============================] - 1s 129us/step - loss: 0.0679 - acc: 0.9747 - val_loss: 0.9276 - val_acc: 0.8006\n",
      "Epoch 71/100\n",
      "5643/5643 [==============================] - 1s 133us/step - loss: 0.0678 - acc: 0.9734 - val_loss: 0.9250 - val_acc: 0.8006\n",
      "Epoch 72/100\n",
      "5643/5643 [==============================] - 1s 134us/step - loss: 0.0669 - acc: 0.9734 - val_loss: 0.9404 - val_acc: 0.8006\n",
      "Epoch 73/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.0654 - acc: 0.9731 - val_loss: 0.9334 - val_acc: 0.7974\n",
      "Epoch 74/100\n",
      "5643/5643 [==============================] - 1s 127us/step - loss: 0.0647 - acc: 0.9748 - val_loss: 0.9387 - val_acc: 0.8022\n",
      "Epoch 75/100\n",
      "5643/5643 [==============================] - 1s 136us/step - loss: 0.0638 - acc: 0.9754 - val_loss: 0.9307 - val_acc: 0.8022\n",
      "Epoch 76/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.0632 - acc: 0.9732 - val_loss: 0.9364 - val_acc: 0.8006\n",
      "Epoch 77/100\n",
      "5643/5643 [==============================] - 1s 135us/step - loss: 0.0625 - acc: 0.9734 - val_loss: 0.9445 - val_acc: 0.7974\n",
      "Epoch 78/100\n",
      "5643/5643 [==============================] - 1s 132us/step - loss: 0.0613 - acc: 0.9747 - val_loss: 0.9519 - val_acc: 0.8054\n",
      "Epoch 79/100\n",
      "5643/5643 [==============================] - 1s 133us/step - loss: 0.0604 - acc: 0.9759 - val_loss: 0.9539 - val_acc: 0.8022\n",
      "Epoch 80/100\n",
      "5643/5643 [==============================] - 1s 135us/step - loss: 0.0611 - acc: 0.9734 - val_loss: 0.9503 - val_acc: 0.8022\n",
      "Epoch 81/100\n",
      "5643/5643 [==============================] - 1s 133us/step - loss: 0.0597 - acc: 0.9750 - val_loss: 0.9506 - val_acc: 0.8054\n",
      "Epoch 82/100\n",
      "5643/5643 [==============================] - 1s 136us/step - loss: 0.0594 - acc: 0.9731 - val_loss: 0.9528 - val_acc: 0.8054\n",
      "Epoch 83/100\n",
      "5643/5643 [==============================] - 1s 132us/step - loss: 0.0590 - acc: 0.9738 - val_loss: 0.9537 - val_acc: 0.8038\n",
      "Epoch 84/100\n",
      "5643/5643 [==============================] - 1s 136us/step - loss: 0.0588 - acc: 0.9741 - val_loss: 0.9435 - val_acc: 0.8038\n",
      "Epoch 85/100\n",
      "5643/5643 [==============================] - 1s 130us/step - loss: 0.0579 - acc: 0.9738 - val_loss: 0.9461 - val_acc: 0.8038\n",
      "Epoch 86/100\n",
      "5643/5643 [==============================] - 1s 138us/step - loss: 0.0571 - acc: 0.9755 - val_loss: 0.9642 - val_acc: 0.8022\n",
      "Epoch 87/100\n",
      "5643/5643 [==============================] - 1s 131us/step - loss: 0.0572 - acc: 0.9731 - val_loss: 0.9586 - val_acc: 0.8006\n",
      "Epoch 88/100\n",
      "5643/5643 [==============================] - 1s 154us/step - loss: 0.0561 - acc: 0.9750 - val_loss: 0.9512 - val_acc: 0.8054\n",
      "Epoch 89/100\n",
      "5643/5643 [==============================] - 1s 148us/step - loss: 0.0566 - acc: 0.9729 - val_loss: 0.9677 - val_acc: 0.7974\n",
      "Epoch 90/100\n",
      "5643/5643 [==============================] - 1s 150us/step - loss: 0.0559 - acc: 0.9745 - val_loss: 0.9465 - val_acc: 0.8006\n",
      "Epoch 91/100\n",
      "5643/5643 [==============================] - 1s 143us/step - loss: 0.0556 - acc: 0.9761 - val_loss: 0.9470 - val_acc: 0.8038\n",
      "Epoch 92/100\n",
      "5643/5643 [==============================] - 1s 160us/step - loss: 0.0549 - acc: 0.9754 - val_loss: 0.9607 - val_acc: 0.7990\n",
      "Epoch 93/100\n",
      "5643/5643 [==============================] - 1s 155us/step - loss: 0.0544 - acc: 0.9743 - val_loss: 0.9688 - val_acc: 0.7990\n",
      "Epoch 94/100\n",
      "5643/5643 [==============================] - 1s 145us/step - loss: 0.0547 - acc: 0.9752 - val_loss: 0.9592 - val_acc: 0.8022\n",
      "Epoch 95/100\n",
      "5643/5643 [==============================] - 1s 139us/step - loss: 0.0541 - acc: 0.9763 - val_loss: 0.9634 - val_acc: 0.8006\n",
      "Epoch 96/100\n",
      "5643/5643 [==============================] - 1s 141us/step - loss: 0.0534 - acc: 0.9764 - val_loss: 0.9514 - val_acc: 0.8006\n",
      "Epoch 97/100\n",
      "5643/5643 [==============================] - 1s 136us/step - loss: 0.0532 - acc: 0.9771 - val_loss: 0.9635 - val_acc: 0.8070\n",
      "Epoch 98/100\n",
      "5643/5643 [==============================] - 1s 142us/step - loss: 0.0534 - acc: 0.9748 - val_loss: 0.9655 - val_acc: 0.8022\n",
      "Epoch 99/100\n",
      "5643/5643 [==============================] - 1s 136us/step - loss: 0.0532 - acc: 0.9747 - val_loss: 0.9629 - val_acc: 0.8022\n",
      "Epoch 100/100\n",
      "5643/5643 [==============================] - 1s 145us/step - loss: 0.0533 - acc: 0.9747 - val_loss: 0.9694 - val_acc: 0.8038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef07413940>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),    \n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
