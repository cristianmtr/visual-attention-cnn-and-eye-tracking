{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all fixations (and normalize them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import glob\n",
    "import sys\n",
    "from scipy import io\n",
    "import math\n",
    "from skimage import transform\n",
    "import random\n",
    "import keras\n",
    "from sklearn import preprocessing\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "POET_DIR = \"D:/data/POETdataset/\"\n",
    "pascal_images = os.path.join(POET_DIR, 'PascalImages')\n",
    "CLASS2IDX_FILE = os.path.join(POET_DIR, 'class2idx.npy')\n",
    "IDX2CLASS_FILE = os.path.join(POET_DIR, 'idx2class.npy')\n",
    "PATCH_SIZE = 78\n",
    "HALF_PATCH = PATCH_SIZE//2\n",
    "DATASET_SIZE = 6270\n",
    "VALIDATION_PERC = 0.2\n",
    "# MAX_GAZE_POINTS = 3 # TEMPORARY\n",
    "MIN_GAZE_POINTS = 2\n",
    "BATCH_SIZE = 50\n",
    "os.chdir(POET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(POET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [a.split(\"_\")[1].split(\".mat\")[0] for a in glob.glob(\"etData/*\")]\n",
    "idx2class = {i:c for i, c in enumerate(classes)}\n",
    "class2idx = {c:i for i, c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixation_within_image(fx, fy, dims):\n",
    "#   print(dims)\n",
    "  if fx < 0:\n",
    "    return False\n",
    "  if fx > dims[1]:\n",
    "    return False\n",
    "  if fy < 0:\n",
    "    return False\n",
    "  if fy > dims[0]:\n",
    "    return False\n",
    "\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_fixations(fixR, fixL, dims):\n",
    "    # ger average of fixations between right and left eye\n",
    "    # manage nans\n",
    "    fix = []\n",
    "    for i in range(len(fixR)):\n",
    "        fR = fixR[i]\n",
    "        fL = fixL[i]\n",
    "        fx = None\n",
    "        fy = None\n",
    "        # no fixations outside\n",
    "        if not np.isnan(fR[0]) and not np.isnan(fL[0]):\n",
    "            fx = np.mean([fR[0],fL[0]])\n",
    "        else:\n",
    "            if np.isnan(fR[0]):\n",
    "                fx = fL[0]\n",
    "            elif np.isnan(fL[0]):\n",
    "                fx = fR[0]\n",
    "                \n",
    "        if not np.isnan(fR[1]) and not np.isnan(fL[1]):\n",
    "            fy = np.mean([fR[1],fL[1]])\n",
    "        else:\n",
    "            if np.isnan(fR[1]):\n",
    "                fy = fL[1]\n",
    "            elif np.isnan(fL[1]):\n",
    "                fy = fR[1]\n",
    "        if fixation_within_image(fx, fy, dims):\n",
    "            fix.append([fx,fy])\n",
    "\n",
    "    fix = np.array(fix)\n",
    "    return fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_matrices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixations(filename, classname, dims):\n",
    "    filename = filename.split(\"%s_\" %classname)[1]\n",
    "    filename = filename.split('.')[0]\n",
    "    if classname not in class_matrices.keys():\n",
    "        c_instances = io.loadmat(os.path.join(POET_DIR,'etData','etData_%s.mat' %classname), squeeze_me=True)['etData']\n",
    "        class_matrices[classname] = c_instances\n",
    "    else:\n",
    "        c_instances = class_matrices[classname]\n",
    "\n",
    "    for i in c_instances:\n",
    "        if filename == i['filename']:\n",
    "            # get fastest user with at least X fixations\n",
    "            sorted_indexes = np.argsort(i['rt'])\n",
    "            for u_i in sorted_indexes:\n",
    "                fixR = i['fixations'][u_i]['imgCoord']['fixR'].tolist()['pos'].tolist().tolist()\n",
    "                fixL = i['fixations'][u_i]['imgCoord']['fixL'].tolist()['pos'].tolist().tolist()\n",
    "                if len(fixR) > 0 and len(fixL) > 0:\n",
    "                    if type(fixR[0]) is list and type(fixL[0]) is list:\n",
    "                        fix = get_avg_fixations(fixR, fixL, dims)\n",
    "                        if len(fix) >= MIN_GAZE_POINTS:\n",
    "                            for f_point in fix:\n",
    "                                f_point[0] = f_point[0]/dims[1]\n",
    "                                f_point[1] = f_point[1]/dims[0]\n",
    "                            return fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = pickle.load(open(\"train_ids.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = pickle.load(open('test_ids.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['horse_2010_004477.jpg',\n",
       "  'cat_2010_001351.jpg',\n",
       "  'horse_2008_006434.jpg',\n",
       "  'dog_2010_002586.jpg',\n",
       "  'cat_2008_007239.jpg',\n",
       "  'cat_2010_002305.jpg',\n",
       "  'cat_2009_003419.jpg',\n",
       "  'sofa_2008_004670.jpg',\n",
       "  'cow_2009_003189.jpg',\n",
       "  'dog_2010_002808.jpg'],\n",
       " ['sofa_2009_001376.jpg',\n",
       "  'diningtable_2010_002880.jpg',\n",
       "  'motorbike_2008_004554.jpg',\n",
       "  'cow_2010_003345.jpg',\n",
       "  'cat_2008_002668.jpg',\n",
       "  'dog_2008_003665.jpg',\n",
       "  'dog_2011_001543.jpg',\n",
       "  'cat_2010_001457.jpg',\n",
       "  'dog_2010_000395.jpg',\n",
       "  'cat_2010_004816.jpg'])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids[:10], test_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/data/POETdataset/PascalImages\\\\aeroplane_2008_000021.jpg',\n",
       " 'D:/data/POETdataset/PascalImages\\\\aeroplane_2008_000033.jpg',\n",
       " 'D:/data/POETdataset/PascalImages\\\\aeroplane_2008_000037.jpg',\n",
       " 'D:/data/POETdataset/PascalImages\\\\aeroplane_2008_000064.jpg',\n",
       " 'D:/data/POETdataset/PascalImages\\\\aeroplane_2008_000151.jpg',\n",
       " 'D:/data/POETdataset/PascalImages\\\\aeroplane_2008_000197.jpg',\n",
       " 'D:/data/POETdataset/PascalImages\\\\aeroplane_2008_000251.jpg',\n",
       " 'D:/data/POETdataset/PascalImages\\\\aeroplane_2008_000291.jpg',\n",
       " 'D:/data/POETdataset/PascalImages\\\\aeroplane_2008_000367.jpg',\n",
       " 'D:/data/POETdataset/PascalImages\\\\aeroplane_2008_000585.jpg']"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aeroplane',\n",
       " 'bicycle',\n",
       " 'boat',\n",
       " 'cat',\n",
       " 'cow',\n",
       " 'diningtable',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'motorbike',\n",
       " 'sofa']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\data\\\\POETdataset\\\\PascalImages\\\\cat_2008_005460.jpg'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5517/5517 [00:32<00:00, 168.74it/s]\n"
     ]
    }
   ],
   "source": [
    "for fn in tqdm.tqdm(train_ids):\n",
    "    full_fn = os.path.abspath(os.path.join(POET_DIR, \"PascalImages\", fn))\n",
    "    for cname in classes:\n",
    "        if cname in full_fn:\n",
    "            img_src = keras.preprocessing.image.img_to_array(\n",
    "                keras.preprocessing.image.load_img(full_fn)\n",
    "            )\n",
    "            fix = get_fixations(full_fn, cname, (img.shape[0],img.shape[1]))\n",
    "            train_fix.append(fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_fix, open(\"train_fix.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 614/614 [00:03<00:00, 156.84it/s]\n"
     ]
    }
   ],
   "source": [
    "for fn in tqdm.tqdm(test_ids):\n",
    "    full_fn = os.path.abspath(os.path.join(POET_DIR, \"PascalImages\", fn))\n",
    "    for cname in classes:\n",
    "        if cname in full_fn:\n",
    "            img_src = keras.preprocessing.image.img_to_array(\n",
    "                keras.preprocessing.image.load_img(full_fn)\n",
    "            )\n",
    "            fix = get_fixations(full_fn, cname, (img.shape[0],img.shape[1]))\n",
    "            test_fix.append(fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test_ids, open(\"test_fix.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_fix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ff1f1ee5bf04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_fix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"go fuck yourself\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_fix' is not defined"
     ]
    }
   ],
   "source": [
    "for f in test_fix:\n",
    "    if len(f) == 0:\n",
    "        print(\"go fuck yourself\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-341-6b3c4519c393>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mflat_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_fix\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-341-6b3c4519c393>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mflat_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_fix\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "flat_list = [item for sublist in test_fix for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-340-ddca549c74f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_fix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "np.max(test_fix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
