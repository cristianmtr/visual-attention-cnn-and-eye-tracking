{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import glob, os, sys\n",
    "import pickle\n",
    "from subprocess import call\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50 as resnet\n",
    "from keras.applications.resnet50 import preprocess_input as resnet_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model by adding preprocessing before the pretrained CNN\n",
    "def get_feature_extraction_model():\n",
    "    cnn_object, pp_function, img_size = _get_pretrained_model()\n",
    "    model = keras.models.Sequential()\n",
    "    cnn_model = cnn_object(weights='imagenet', include_top=False, pooling='max')\n",
    "    model.add(keras.layers.Lambda(pp_function, name='preprocessing', input_shape=(img_size, img_size, 3)))\n",
    "    model.add(cnn_model)\n",
    "    return model\n",
    "\n",
    "# Unpacking information from the models dictionary\n",
    "def _get_pretrained_model():\n",
    "    cnn_object = resnet\n",
    "    pp_function = resnet_pp\n",
    "    img_size = 224\n",
    "    return cnn_object, pp_function, img_size\n",
    "\n",
    "def get_features(files, model):\n",
    "    # Load images based on the size of the Lambda layer \n",
    "    # provided as the first layer before the pretrained CNN\n",
    "    x = np.array([image.img_to_array(image.load_img(file, target_size=(model.layers[0].input_shape[1], model.layers[0].input_shape[1]))) for file in files])\n",
    "    return model.predict(x, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
